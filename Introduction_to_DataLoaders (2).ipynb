{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "c7eb2650",
      "metadata": {
        "id": "c7eb2650"
      },
      "source": [
        "# Introduction to DeepChem DataLoaders\n",
        "\n",
        "This tutorial introduces the `DataLoader` class that DeepChem uses to load and prepare data for machine learning. DataLoaders automate the process of reading files, converting molecules to numerical features, handling missing values, and managing memory efficiently. Understanding DataLoaders is essential for working with your own datasets in DeepChem.\n",
        "\n",
        "## Colab\n",
        "\n",
        "This tutorial and the rest in this sequence can be done in Google colab. If you'd like to open this notebook in colab, you can use the following link.\n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1EKssZcHHf59GkvaZlXzuEZ6jwV7laDpf?usp=sharing)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from rdkit import RDLogger\n",
        "import warnings\n",
        "\n",
        "# Disable ALL RDKit logs (C++ and Python)\n",
        "RDLogger.DisableLog('rdApp.*')\n",
        "\n",
        "# Also ignore Python warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "metadata": {
        "id": "6nUhZeuxsMWK"
      },
      "id": "6nUhZeuxsMWK",
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "id": "4c8e49f6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4c8e49f6",
        "outputId": "20be98f8-bb7b-490a-caa1-65474b7b3720"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: deepchem in /usr/local/lib/python3.12/dist-packages (2.8.1.dev20251027190029)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (from deepchem) (1.5.2)\n",
            "Requirement already satisfied: numpy<2 in /usr/local/lib/python3.12/dist-packages (from deepchem) (1.26.4)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from deepchem) (2.2.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (from deepchem) (1.6.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.12/dist-packages (from deepchem) (1.13.3)\n",
            "Requirement already satisfied: scipy>=1.10.1 in /usr/local/lib/python3.12/dist-packages (from deepchem) (1.16.3)\n",
            "Requirement already satisfied: rdkit in /usr/local/lib/python3.12/dist-packages (from deepchem) (2025.9.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->deepchem) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->deepchem) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->deepchem) (2025.2)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.12/dist-packages (from rdkit->deepchem) (11.3.0)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->deepchem) (3.6.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy->deepchem) (1.3.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->deepchem) (1.17.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install --pre deepchem"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "id": "12408e18",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "12408e18",
        "outputId": "5a658d4e-2a3c-4ea7-98c7-80e90c517055"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DeepChem version: 2.8.1.dev\n"
          ]
        }
      ],
      "source": [
        "import deepchem as dc\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "print(f\"DeepChem version: {dc.__version__}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "caeb00e7",
      "metadata": {
        "id": "caeb00e7"
      },
      "source": [
        "## What is a DataLoader?\n",
        "\n",
        "A DataLoader is DeepChem's tool for preparing raw data files for machine learning. It handles the entire pipeline from file to ML-ready dataset:\n",
        "\n",
        "```\n",
        "Raw File (CSV/SDF/JSON) → DataLoader → Dataset → Model Training\n",
        "```\n",
        "\n",
        "When working with molecular data, you typically need to load chemical structures from files, convert them to numerical features, extract labels, handle missing or invalid data, and manage memory for large datasets. Writing this code manually is time-consuming and error-prone. DataLoaders automate all of these steps.\n",
        "\n",
        "In this tutorial, we'll explore how to use DataLoaders effectively with your own data."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8e79df06",
      "metadata": {
        "id": "8e79df06"
      },
      "source": [
        "## CSVLoader: The Basics\n",
        "\n",
        "The most commonly used DataLoader in DeepChem is CSVLoader, which handles tabular datasets, especially those containing SMILES strings and molecular properties.\n",
        "\n",
        "To understand how CSVLoader works, we’ll start with a small, custom-made CSV example.\n",
        "Using a tiny dataset makes it easier to clearly see how DeepChem loads features, tasks, and shapes before we move on to larger real-world datasets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "id": "33e11075",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "33e11075",
        "outputId": "b573e711-3748-4e22-f78c-44fb79d1b9a6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Example dataset:\n",
            "  compound_id smiles  solubility  toxicity\n",
            "0        mol1    CCO       -0.77         0\n",
            "1        mol2     CC       -1.38         1\n",
            "2        mol3      C       -0.33         0\n",
            "3        mol4   CCCC       -1.69         1\n",
            "4        mol5    CCC       -1.00         0\n"
          ]
        }
      ],
      "source": [
        "# Create a simple molecular dataset\n",
        "data = {\n",
        "    'compound_id': ['mol1', 'mol2', 'mol3', 'mol4', 'mol5'],\n",
        "    'smiles': ['CCO', 'CC', 'C', 'CCCC', 'CCC'],\n",
        "    'solubility': [-0.77, -1.38, -0.33, -1.69, -1.00],\n",
        "    'toxicity': [0, 1, 0, 1, 0]\n",
        "}\n",
        "df = pd.DataFrame(data)\n",
        "df.to_csv('example_data.csv', index=False)\n",
        "\n",
        "print(\"Example dataset:\")\n",
        "print(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that we have a small custom dataset saved as example_data.csv, we can use DeepChem’s CSVLoader to read the file and convert the SMILES strings into molecular features. The loader will automatically featurize each molecule, extract the target columns, and return a DeepChem Dataset object that we can use for training models."
      ],
      "metadata": {
        "id": "O1F5fLSVxPFC"
      },
      "id": "O1F5fLSVxPFC"
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "id": "494caaaa",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "494caaaa",
        "outputId": "8ac51b12-a08b-4f43-a827-d752d1cfeebb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset created with 5 samples\n",
            "Tasks: ['solubility' 'toxicity']\n",
            "Feature shape: (5, 1024)\n",
            "Label shape: (5, 2)\n",
            "Weight shape: (5, 2)\n"
          ]
        }
      ],
      "source": [
        "featurizer = dc.feat.CircularFingerprint(size=1024)\n",
        "\n",
        "# Create the CSVLoader\n",
        "loader = dc.data.CSVLoader(\n",
        "    tasks=['solubility', 'toxicity'],  # Columns to use as prediction targets (can be multiple)\n",
        "    feature_field='smiles',            # Column containing molecules\n",
        "    featurizer=featurizer,             # How to convert molecules to features\n",
        "    id_field='compound_id'             # Column containing identifiers\n",
        ")\n",
        "\n",
        "# Load the data\n",
        "dataset = loader.create_dataset('example_data.csv')\n",
        "\n",
        "print(f\"Dataset created with {len(dataset)} samples\")\n",
        "print(f\"Tasks: {dataset.tasks}\")\n",
        "print(f\"Feature shape: {dataset.X.shape}\")\n",
        "print(f\"Label shape: {dataset.y.shape}\")\n",
        "print(f\"Weight shape: {dataset.w.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d1c081ad",
      "metadata": {
        "id": "d1c081ad"
      },
      "source": [
        "The DataLoader automatically performed several operations:\n",
        "\n",
        "1. **Featurization**: Converted SMILES strings into 1024-dimensional fingerprint vectors using the CircularFingerprint (ECFP) algorithm\n",
        "2. **Label extraction**: Extracted the values from both task columns (solubility and toxicity) as labels\n",
        "3. **Weight creation**: Created weight arrays to indicate valid data points\n",
        "4. **ID preservation**: Kept the compound IDs for reference\n",
        "5. **Data cleaning**: Invalid SMILES are filtered out, and missing values are set to 0 with weights set to 0 (telling the model to ignore them during training)\n",
        "\n",
        "The `tasks` parameter accepts a list of column names. You can specify one task for single-task learning or multiple tasks to train a model that predicts several properties simultaneously. Let's examine the data:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "id": "2658bdd5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2658bdd5",
        "outputId": "2e600bf8-7c05-4cf5-c6dc-683934e23b7c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First molecule's fingerprint (first 20 values):\n",
            "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "\n",
            "Labels for all molecules:\n",
            "[[-0.77  0.  ]\n",
            " [-1.38  1.  ]\n",
            " [-0.33  0.  ]\n",
            " [-1.69  1.  ]\n",
            " [-1.    0.  ]]\n",
            "(Each row: [solubility, toxicity])\n",
            "\n",
            "Molecule IDs:\n",
            "['mol1' 'mol2' 'mol3' 'mol4' 'mol5']\n"
          ]
        }
      ],
      "source": [
        "print(\"First molecule's fingerprint (first 20 values):\")\n",
        "print(dataset.X[0][:20])\n",
        "\n",
        "print(\"\\nLabels for all molecules:\")\n",
        "print(dataset.y)\n",
        "print(\"(Each row: [solubility, toxicity])\")\n",
        "\n",
        "print(\"\\nMolecule IDs:\")\n",
        "print(dataset.ids)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9731b769",
      "metadata": {
        "id": "9731b769"
      },
      "source": [
        "## Working with Real Datasets\n",
        "\n",
        "In the previous example, we used a small custom dataset to understand how CSVLoader works and to get a clear idea of how DeepChem processes SMILES strings, featurizes molecules, and builds a Dataset object.\n",
        "\n",
        "Now let’s move beyond the toy example and load a real-world molecular dataset. This will show how DataLoaders behave at scale, how they handle larger files, and how the same workflow applies to practical chemistry/ML tasks."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "id": "678c96c4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "678c96c4",
        "outputId": "188faa0d-079e-407f-f65f-d528cc739706"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Delaney dataset loaded with 1128 molecules\n",
            "Columns: ['Compound ID', 'ESOL predicted log solubility in mols per litre', 'Minimum Degree', 'Molecular Weight', 'Number of H-Bond Donors', 'Number of Rings', 'Number of Rotatable Bonds', 'Polar Surface Area', 'measured log solubility in mols per litre', 'smiles']\n"
          ]
        }
      ],
      "source": [
        "import urllib.request\n",
        "import pandas as pd\n",
        "\n",
        "url = 'https://deepchemdata.s3-us-west-1.amazonaws.com/datasets/delaney-processed.csv'\n",
        "dataset_file = 'delaney-processed.csv'\n",
        "\n",
        "urllib.request.urlretrieve(url, dataset_file)\n",
        "\n",
        "df_delaney = pd.read_csv(dataset_file)\n",
        "print(f\"Delaney dataset loaded with {len(df_delaney)} molecules\")\n",
        "print(f\"Columns: {df_delaney.columns.tolist()}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "id": "d9803f84",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d9803f84",
        "outputId": "000f78b1-057c-4518-d495-a97f9da0d95d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded 1128 molecules\n",
            "Feature shape: (1128, 1024)\n",
            "Task: ['measured log solubility in mols per litre']\n"
          ]
        }
      ],
      "source": [
        "loader_delaney = dc.data.CSVLoader(\n",
        "    tasks=['measured log solubility in mols per litre'],\n",
        "    feature_field='smiles',\n",
        "    featurizer=dc.feat.CircularFingerprint(size=1024)\n",
        ")\n",
        "\n",
        "dataset_delaney = loader_delaney.create_dataset(dataset_file)\n",
        "\n",
        "print(f\"Loaded {len(dataset_delaney)} molecules\")\n",
        "print(f\"Feature shape: {dataset_delaney.X.shape}\")\n",
        "print(f\"Task: {dataset_delaney.tasks}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "After loading the dataset, we now have a full DeepChem Dataset object containing featurized SMILES strings and the target solubility values. At this point, you can inspect the features, run quick sanity checks, or plug the dataset directly into a model. This confirms that the same loading process we used for the toy example scales cleanly to real-world molecular data.\n",
        "\n",
        "Now that the basic loading pipeline is clear, let’s look at an important practical aspect: memory management. When datasets get large, loading everything at once isn’t always ideal, so DeepChem provides sharding support to handle data efficiently."
      ],
      "metadata": {
        "id": "OIiCsM0Zzpmh"
      },
      "id": "OIiCsM0Zzpmh"
    },
    {
      "cell_type": "markdown",
      "id": "b070537f",
      "metadata": {
        "id": "b070537f"
      },
      "source": [
        "## Memory Management: Sharding\n",
        "\n",
        "For very large datasets that don't fit in memory, DataLoaders use a technique called \"sharding\". The data is processed in chunks (shards), and each shard is saved to disk separately. This allows you to work with datasets much larger than your available RAM."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "id": "14286215",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "14286215",
        "outputId": "0c926047-063c-4e09-9167-b3f40f3bafcf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total molecules: 1128\n",
            "Number of shards: 23\n",
            "Shard size: 50\n",
            "Data directory: /tmp/tmpyfa57n6j\n"
          ]
        }
      ],
      "source": [
        "# Control shard size for memory management\n",
        "dataset_sharded = loader_delaney.create_dataset(\n",
        "    dataset_file,\n",
        "    shard_size=50  # Process 50 molecules at a time\n",
        ")\n",
        "\n",
        "print(f\"Total molecules: {len(dataset_sharded)}\")\n",
        "print(f\"Number of shards: {dataset_sharded.get_number_shards()}\")\n",
        "print(f\"Shard size: {dataset_sharded.get_shard_size()}\")\n",
        "print(f\"Data directory: {dataset_sharded.data_dir}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "52eecf8c",
      "metadata": {
        "id": "52eecf8c"
      },
      "source": [
        "The default shard size is 8192. Use smaller values if you encounter memory issues, or larger values if you have plenty of memory and want faster processing."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8106851b",
      "metadata": {
        "id": "8106851b"
      },
      "source": [
        "## Other DataLoader Types\n",
        "\n",
        "While CSVLoader is the most common, DeepChem provides specialized loaders for other file formats:\n",
        "\n",
        "- **SDFLoader**: For 3D molecular structures in SDF format (commonly used in drug discovery)\n",
        "- **InMemoryLoader**: For data already loaded in Python (lists, arrays, DataFrames)\n",
        "- **JsonLoader**: For JSON files with nested data structures\n",
        "- **ImageLoader**: For image data (microscopy, cell images)\n",
        "- **FASTALoader, FASTQLoader**: For DNA/protein sequences\n",
        "\n",
        "Let's see how to load data from a different format. Here's an example using SDFLoader with an actual molecular dataset:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "id": "848a29ad",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "848a29ad",
        "outputId": "85e4e672-6379-47dd-9f72-78864e87e475"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded 991 molecules from SDF file\n",
            "Feature shape: (991, 1024)\n"
          ]
        }
      ],
      "source": [
        "import urllib.request\n",
        "\n",
        "# Download an SDF dataset\n",
        "url = 'https://deepchemdata.s3-us-west-1.amazonaws.com/datasets/gdb1k.sdf'\n",
        "sdf_file = 'example_mols.sdf'\n",
        "\n",
        "urllib.request.urlretrieve(url, sdf_file)\n",
        "\n",
        "# Create the SDFLoader\n",
        "sdf_loader = dc.data.SDFLoader(\n",
        "    tasks=[],  # No prediction tasks for this example\n",
        "    featurizer=dc.feat.CircularFingerprint(size=1024),\n",
        "    sanitize=True\n",
        ")\n",
        "\n",
        "# Load the SDF dataset\n",
        "dataset_sdf = sdf_loader.create_dataset(sdf_file)\n",
        "\n",
        "print(f\"Loaded {len(dataset_sdf)} molecules from SDF file\")\n",
        "print(f\"Feature shape: {dataset_sdf.X.shape}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This shows how easily DeepChem can load data from an SDF file using the same workflow as CSVs: choose a loader, pick a featurizer, and create the dataset. The same pattern applies to the other loader types as well—whether your data is in JSON, images, FASTA/FASTQ, or even already in memory."
      ],
      "metadata": {
        "id": "_lnJa2Ba1Ysb"
      },
      "id": "_lnJa2Ba1Ysb"
    },
    {
      "cell_type": "markdown",
      "id": "c14202de",
      "metadata": {
        "id": "c14202de"
      },
      "source": [
        "## DataLoaders in MoleculeNet\n",
        "\n",
        "In previous tutorials, you may have seen code like `tasks, datasets, transformers = dc.molnet.load_delaney()` followed by `train, valid, test = datasets`. MoleculeNet functions use DataLoaders internally. When you call `dc.molnet.load_delaney()`, it's using CSVLoader behind the scenes to load and process the data.\n",
        "\n",
        "You can use MoleculeNet for convenience with standard datasets, or use DataLoaders directly when you need custom processing or are working with your own data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "id": "3b6a7d24",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3b6a7d24",
        "outputId": "7f505c86-f985-432f-d1bc-97990fc06fe6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MoleculeNet approach:\n",
            "Training set: 902 molecules\n",
            "\n",
            "Manual DataLoader approach:\n",
            "Training set: 902 molecules\n"
          ]
        }
      ],
      "source": [
        "# MoleculeNet approach (convenient)\n",
        "tasks_mol, datasets_mol, transformers = dc.molnet.load_delaney(\n",
        "    featurizer='ECFP',\n",
        "    splitter='random'\n",
        ")\n",
        "train_mol, valid_mol, test_mol = datasets_mol\n",
        "\n",
        "print(\"MoleculeNet approach:\")\n",
        "print(f\"Training set: {len(train_mol)} molecules\")\n",
        "\n",
        "# Manual DataLoader approach (more control)\n",
        "loader = dc.data.CSVLoader(\n",
        "    tasks=['measured log solubility in mols per litre'],\n",
        "    feature_field='smiles',\n",
        "    featurizer=dc.feat.CircularFingerprint(size=1024)\n",
        ")\n",
        "\n",
        "full_dataset = loader.create_dataset(dataset_file)\n",
        "splitter = dc.splits.RandomSplitter()\n",
        "train_manual, valid_manual, test_manual = splitter.train_valid_test_split(full_dataset)\n",
        "\n",
        "print(\"\\nManual DataLoader approach:\")\n",
        "print(f\"Training set: {len(train_manual)} molecules\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fad8f319",
      "metadata": {
        "id": "fad8f319"
      },
      "source": [
        "## Summary\n",
        "\n",
        "DataLoaders automate the process of preparing molecular data for machine learning:\n",
        "\n",
        "- **CSVLoader** is the most commonly used for tabular data\n",
        "- Automatic **featurization** converts molecules to numerical representations\n",
        "- **Missing values** and invalid molecules are handled automatically\n",
        "- **Sharding** enables processing of large datasets that don't fit in memory\n",
        "- **Multi-task** learning is supported by specifying multiple task columns\n",
        "- MoleculeNet uses DataLoaders internally for standard benchmarks\n",
        "\n",
        "For most applications, you'll use CSVLoader with your own datasets or rely on MoleculeNet for standard benchmarks."
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}